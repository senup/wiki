---
title: kafka
date: 2023-12-22 12:35:10
tags:
  - tech
Draft: true
HideInList: false
Feature: 
IsTop: false
---

## 面试题

1. 保证 Kafka 的高可用：Kafka 支持集群模式，当某个节点（Kafka 的节点叫 Broker 啊！）出问题时，Kafka 会自动将该 Broker 上的分区转移到其他健康的 Broker 上。这就像你玩拼图，如果一块丢了，你可以用其它的来补齐。
2. 避免重复消费：Kafka 的消息消费本质上是通过 offset（偏移量）来控制的。每个 Consumer 会专心记住它读到哪里，就像你阅读一本书，用书签标记了你阅读的位置一样。所以，只要不重置 offset，就不会重复消费消息。
3. 确保幂等性：Kafka 0.11 版本以后支持了幂等写入，可以通过设置`enable.idempotence=true`来启用。消费端的幂等性则需要你在业务层面来保证，比如在数据库进行操作时，考虑将数据库操作设置为幂等操作。
4. 保证消息的可靠性传输：Kafka 提供了消息持久化的功能，即把数据写入磁盘。并且还提供了数据副本，这就保证了即使某个 Broker 挂了，消息也不会丢失。你还可以设置 acks 参数来控制消息确认的模式，比如设置为'all'，就要等所有的 follower 都确认后才算消息写入成功。
5. 消息丢失怎么办：Kafka 通过 Replica 机制保证了消息的安全，即使有 Broker 宕机，由于有 Replica，所以消息不会丢。但是如果你的 Replica 也丢了，那就真的找不回来了，尽管这种概率非常小。你可以设置更大的`replication.factor`来减少这种风险，就像你的钥匙丢了，如果你有备用钥匙，那就不怕了。

---

1. 保证消息的顺序性：在 Kafka 中，每个 Partition 内的消息是有序的，也就是说，消费者在消费某个 Partition 的消息时，是按照消息在 Partition 内的存放顺序进行消费的。就像你在超市购物，你可以先买鸡蛋，然后再买鸡，但在每个货架上，你肯定是从上而下，从左到右地取商品。
2. 解决消息队列的延时问题：在 Kafka 中，一般通过增加 Partition 数量以及增加 Consumer 数量来提高吞吐量，进而降低延时。就像你想快速将一箱苹果分给大家，你会将苹果分成几堆，然后请几个人来帮忙分发。
3. 解决消息队列过期失效问题：Kafka 提供了消息过期机制，你可以设置每个消息的保留时间，所以不用担心消息会无休止地堆积下去。就好比每个人都有生老病死，每个消息也有生存周期。
4. 消息队列满了以后该怎么处理：在 Kafka 中，你可以通过加大存储空间来应对消息堆积。另一种方式是增加消费者数量，以更快地消费掉积压的消息。
5. 几百万消息持续积压几小时怎么解决：同上，你可以试着去调整 Cluster 的大小，也就是增减 Broker 数，亦或者增加 Partition 数，调整你的消费者组来处理这个问题。
6. 写一个消息队列的架构设计：这需要根据不同的场景和需求来考虑，我会考虑如下几点：

   - 高可用性：可以通过多副本以及 leader-follower 模式来保证。
   - 高吞吐量：通过分区并行以及批量处理来提高处理效率。
   - 消息持久化：保证消息不会丢失，可以将其落盘，并保证落盘操作的高效。
   - 消费者群管理：提供有效的消费者群管理，使得消费者能根据自己的需求来高效地消费消息。

在顺序性、延时、过期失效、满队列和消息积压等问题上，你需要找到合适的平衡点。这就像走钢丝，需要细心保持平衡，才能走到对岸。

## 消息中间件的作用

## 核心组件

# 生产数据

来详细了解一下他们：

1. 配置项：

   - bootstrap.servers：这是 Broker 的地址列表，Producer 需要连接到这些地址上去发送消息。
   - acks：这是消息确认机制，可以配置为 0, 1, 或者 all，根据需要选择一种级别。
   - retries：这是生产者在发送失败后，自动重试的次数。
   - batch.size：这是消息发送批次的大小。
   - linger.ms：消息等待发送的最长时间。
   - buffer.memory：这是生产者可以用来缓冲消息的内存大小。

2. 回调函数：当消息被发送之后，Kafka Producer 会调用这个回调函数来通知应用发送的结果，你可以在回调函数中做相应处理，例如记录日志或者统计发送成功的数量。
3. 自定义拦截器：你可以通过实现 ProducerInterceptor 接口来自定义拦截器，拦截器中有以下三个方法：

   - onSend：这个方法在消息被发送之前调用，你可以在这里进行消息的预处理。
   - onAcknowledgement：这个方法在消息被确认后调用，你可以在这里进行统计或者其他操作。
   - close：这个方法在生产者关闭时调用，一般可以用来做一些清理工作。

4. 自定义分区：你可以通过实现 Partitioner 接口来自定义分区器，分区器中有以下两个方法：

   - partition: 这个方法用于决定消息应该发送到哪个分区。
   - close：这个方法和拦截器的 close 方法类似，都是在生产者关闭时进行调用的。

在发送消息的过程中，这些工具可以帮助你更好地控制消息的发送和处理

## 消费数据

1. 拉取数据：Kafka 中的 Consumer 从 Broker 拉取数据时，首先需要知道要拉取哪个 Topic 的哪个 Partition，同时需要提供一个 Offset。这就好像你去邮局取信，你需要知道你的邮箱号（Partition)，并要从哪封信开始取（Offset）。
2. 查找数据的过程：Kafka 的数据存储是按照 Topic 和 Partition 来组织的。你可以把每个 Partition 想象成一本书，每个消息就是书中的一页，而 Offset 就是页码。消费者根据 Topic、Partition 和 Offset 可以精确地找到需要的数据。
3. 文件结构：Kafka 中的每个 partition 对应一个文件夹，文件夹下面的每个文件代表一个 segment，每个 segment 文件对应两个文件，一个保存的是消息数据，一个保存的是索引。
4. 记录消费的位置：Kafka 通过 Offset 来记录消费的位置。你可以将 Offset 想象成书签，这样，下次你继续阅读时，就可以直接从书签处开始。
5. 消息的提交：消息提交就是更新 Offset。Kafka 支持同步提交和异步提交两种方式。同步提交虽然可靠，但效率低；异步提交效率高，但可能会丢失一些消息。
6. 保证幂等性：在消费者端，幂等性通过业务逻辑来保证。例如，如果你的操作是向数据库中插入一条记录，那么你可以设置主键冲突时忽略，这样即使插入多次，数据库中也只会有一条记录。
7. 提交与消费的顺序：消费消息和提交 offset 是两个步骤，通常我们消费完消息再提交 offset。这样可以确保如果在消费过程中出问题，我们可以通过重设 offset 再次消费该消息。
8. 消费者重平衡：在 Consumer Group 中，如果有新的消费者加入、已有的消费者退出，或者订阅的 Topic 的 Partition 数目发生变化，那么就会触发消费者重平衡。处理方式，Kafka 提供了 Rebalance Listener，我们可以在 Listener 中定义在重平衡之前和之后要执行的操作。

消费者在获取、处理、提交消息的过程中，就像是在跑马拉松。每个人都有自己的起点（Offset），每个人都需要准备（拉取消息），奔跑（处理消息），并记录自己跑过的路程（提交 Offset）。只有这样，才能确保跑者们在赛道上顺利进行。

## 幂等性

1. 写入的幂等性：Kafka 通过 `enable.idempotence=true` 确保消息生产者的幂等性。这个开关将保证不会因为网络问题等导致的重传造成重复写入。幂等性是由 producer id（pid）和序列号（seq id）一起保证的，Kafka broker 只接受序列号大于当前序列号的记录。
2. 无法保证幂等的特殊情况：如果 producer 重启，pid 可能会变，这时同一条消息可能被重写。另一种场景是，如果消息没有 key，并且消息是轮询写入不同的 partition，由于 Kafka 只保证单个 partition 的顺序，所以可能无法保证全局的幂等性。
3. 保证写入的 exactly once：确保精确一次消费，是通过“At least once”消费语义加上幂等性来完成。也就是说，Kafka 消费者做好消息消费后，可以将 offset 保存下来，即使重启消费者或者重复拉取消息，由于保存下来的 offset，也不会出现重复消费的情况。
4. 零拷贝技术：在 Kafka 中，为了提高数据发送效率，采用了零拷贝技术，这就是将文件直接从磁盘转到 Socket，而不需要将文件从内核空间拷贝到用户空间，然后再从用户空间拷贝到内核空间，从而减少了 CPU 和内存的使用，提高了数据传输效率。
5. Kafka 优化发送消息：有几种策略可以用来优化 Kafka 的发送，比如可以通过调整 batch.size 和 linger.ms 来控制批次发送的大小和延迟，当数据量大到达到 batch.size 或者等待时间超过 linger.ms 时，批次就可以被发送。此外，还可以通过调整 max.request.size 来控制单个请求的最大字节数，从而避免因为单个请求过大而引发的问题。

## 重平衡

关于消费者重平衡，就像大家在拿着一堆糖果，突然有人来了或走了，我们需要重新分配。不过，不用担心，让我来帮你解答：

1. 什么情况会发生消费者重平衡：消费者重平衡可能在以下几种情况下发生：

   - 新的消费者加入 Consumer Group
   - 已存在的消费者离开 Consumer Group
   - 订阅主题的分区数发生变化
   - 订阅的主题列表发生变化

2. 分区和消费者关系：在 Kafka 中，每个消费者都会被分配一个或多个分区，分区的数量是可以动态调整的。消费者的数量不能超过分区的数量，否则会有消费者闲置。比如，你有 3 个分区和 2 个消费者，可能每个消费者都会获得至少一个分区，其中一个消费者可能会获取两个分区。
3. 如何处理消费者重平衡：Kafka 已经很好地处理了消费者重平衡。当发生重平衡的时候，会触发一个再均衡的过程，包括三个阶段：再均衡前（Rebalance Before）、再均衡过程（Rebalance In Progress）、再均衡后（Rebalance After）。在 Rebalance Before 阶段，Consumer 会停止当前消费，提交当前的 offset；Rebalance In Progress 阶段，进行分区分配；Rebalance After 阶段，分配完成后，Consumer 开始从新的分区消费。
4. Kafka 提供了 3 种消费者分配策略：Range、RoundRobin 和 Sticky。Range 策略将所有 Topic 的分区排列成一个列表，然后按照消费者数量进行分割；RoundRobin 策略是把所有 Topic 的所有分区按照 round-robin 方式分配给消费者；Sticky 策略在尽可能减少触发 Rebalance 的同时，尽量均匀地分配分区。

消费者重平衡就好比在为队员分配任务，目标就是让每个人都能有事情做，不会有人闲着，也不会有人忙不过来。这关键的是取得平衡，而这个平衡，正是 Kafka 在追求的。

## 高可用

这就要提到 Kafka 中的 ISR、HW 和 LEO 以及它们之间的关系。

1. ISR：ISR 代表 In-Sync Replica Set，它包含了所有与 leader 保持同步的、可用的 follower 副本，这个列表是动态变化的。
2. LEO：LEO 代表 Last End Offset，表示每个副本最后一个已经写入的消息的 offset。
3. HW：HW 代表 High Watermark，表示已经被所有 ISR 中的副本写入的、最小的 LEO。

你提到的水位流程就是在 ISR、LEO 和 HW 之间形成的。比如说，我们的 ISR 里有三个副本 A，B，C。假设此时他们的 LEO 分别为 5，5，4，那么 HW 就是 4。只有当所有 ISR 里的所有副本的 LEO 都大于 4 时，HW 才会提升。

关于故障处理的问题，Kafka 有以下方式：

1. 当 follower 发生故障：如果 follower 发生故障，将会从 ISR 中被剔除，直到它重新从 Leader 同步数据，并且 LEO 超过 HW 后，才能再次被加入到 ISR 中。
2. 当 leader 发生故障：如果 leader 发生故障，那么会从 ISR 中选举一个新的 leader，进行领导权的切换。

关于消息确认的问题，ack 的值为-1 时，表示所有的副本都需要确认消息写入才算完成。此时如果仅过半数的副本确认，则不能确保所有副本都能正确写入数据，有可能数据丢失。

在配置中，我们可以指定允许的最大故障节点数。这个数值需要根据具体的需求进行设置，一般来说，这个数值不能大于 ISR 的数量，否则可能会导致数据丢失。

最后，关于领导者故障后的场景：如果 ack=0，那么生产者不会等待确认，所以不受影响；则如果 ack=1，那么只要领导者收到消息，生产者就可以确认消息发送成功，但如果此时领导者奔溃，就可能导致数据丢失；如果 ack=-1，那么需要所有的副本都确认后，生产者才能确认消息已发送成功，在领导者奔溃后，将会等待新的领导者选举。

## 发送流程

## 粘包与拆包

"粘包"和"拆包"是网络编程中非常常见的问题。他们就像是生活中乱插队和被强制中断的状况。

"粘包"是指发送方发送的若干包数据到达接收方时粘成一个包，接收方不清楚这是几个包的数据。好比你在超市买了很多商品，但是收银员把他们都算成了一个商品。

"拆包"是指发送方发送的一个完整的包，在发送过程中被拆成了两个或多个包，到达接收方时，接收方无法知道这是一个完整的包。好比你买的一个大包薯片，在途中被拆开成了好几小包。

关于如何解决粘包和拆包的问题，我们有以下几种方法：

1. 定长方式：每次发送固定长度的数据，不足的补空格。这种方式浪费网络资源，但是简单可行。
2. 分隔符方式：每次发送的包数据后面都紧接一个特殊的分隔符，接收方收到数据后根据分隔符判断一个包数据是否结束。这种方式在发送的数据中不能包含分隔符，否则会出错。
3. 头部标记长度方式：每次数据发送前，先发送一个头部信息，头部信息中包含整个数据包的长度。因此，Kafka 里的 Producer 会在发送 Batch 的时候，把 Batch 的总长度写在 Batch 的头部，Broker 就根据这个长度来断定"粘包"的情况。

对于"拆包"问题，Kafka 的解决办法是，Producer 在发送 Request 的时候，如果第一次发送没有完成，它会记住已经发送的位置，下一次继续从这个位置发送。这样就保证了一个 Request 肯定会被完整发送。

## 消息的提交

消息的提交在 Kafka 中是非常重要的，它决定了消息能否被成功消费。消息的提交有同步和异步两种方式，他们就好像是人生中的步行和乘车出行。

1. 同步提交：这如同步行者，他会一步一步地向目的地走去。每走一步，他都会确认这一步脚下的情况。同步提交会在提交完消息后，阻塞当前线程，直到收到 Kafka 的应答。
2. 异步提交：这就像是乘车出行，他们往往将目的地设定好后，就可快速直达。异步提交则是提交完消息后，不会等待 Kafka 的反馈，而是立即返回。

据我之前的经验，很多人都在问：同步和异步提交，我应该选择哪一种？

这就好比问：我应该步行还是乘车出行？这要看你的情况。如果你是散步，想要享受每一步的风景，你应该选择步行，也就是同步提交。同步提交虽然效率低，但是可靠，可以保证你的每一步都是稳定的。如果你是赶路，想要快点到达目的地，你应该选择乘车出行，也就是异步提交。异步提交效率高，但是可能会忽略一些问题，例如你可能会错过中途的风景，或者是在堵车时不知所措。

关于提交和消费的顺序，通常我们先消费消息，再提交 offset。这就好像是你先要看到风景（消费消息），然后再走过去（提交 offset）。这可以防止在你看风景的过程中发生问题，而你已经走过去的状况。

# 特性与通信方式

## 消息中间件的作用

#### 解耦

生产者不需要直接对接消费者, 切断联系；

#### 异步

生产者发送消息，消费者去同步消费消息
中间件天然，可以消费者不需要同步消息，生产者继续异步生产；
这点是消费的时间上来说的；

#### 削峰

中间件也能存储消息，因此进入队列后可以凭借着消费者的消费速度来定。

## 消费队列的两种通信方式

1. 点对点（拉取方式）：在这种模式下，你可以把每个消息想象成一个小旗子，消费者就是在跑步的运动员。运动员每跑过一个小旗子就把它插在路边，而后面的运动员则根据路边插着小旗子的数量来调整自己的速度。在 Kafka 中，消费者消费消息后会提交 offset，以标记已经消费的消息。这种方式的<u>优势</u>在于可以完全适配消费速度，不会占满消费者内存。但是，消费者需要时刻监听队列的数据情况，这会带来一定的性能消耗。（可以通过监听间隔，比如 100ms 再去拉取）
2. 发布订阅（推送方式）：在这种模式下，可以把消息比作是一个个汽球，而消费者就是消费者们手中的刺。消息队列不断地往消费者这边推汽球，消费者就用手中的刺扎破它们。消息队列无需关心消费者的消费速度，只要有新消息就推送出去，充分利用了消费者性能。但是，如果消费者处理不过来，可能会撑爆消费者的内存，造成大量消息堆积。（可以设置缓冲区）

对比来说，RabbitMQ 的拓扑结构包括 Producer、Exchange、Queue 和 Consumer，其中 Producer 负责生产消息，Exchange 负责将消息路由到合适的 Queue，而 Consumer 则负责消费 Queue 中的消息。

# 核心组件

此处需要一个图: 包含 zookeeper，leader，副本；
broker：集群中的一个实例；
topic 可以分散在不同的 broker 上面；
partition 可以有多个副本；

1. **Partition：**  在物理上，Topic 可以进一步细分为一个或多个 Partition。每个 Partition 都是一个有序的、不可改变的消息队列，消息都被不断地追加到 Partition 中。Partition 在底层实现上就是一个个分割的 segment 文件。
2. **Replica：** Kafka 提供了消息的备份机制，也就是将数据复制到多个 broker 上，以防某一 broker 宕机，可以从其他 broker 获取数据，该备份称为 Replica。
3. **Leader 和 Follower：**  在多个 Replica 中，会选举出一个 Leader，其他的 Replica 作为 Follower。Producer 与 Leader 进行交互来传送数据，Consumer 则从 Leader 或者 Follower 获取数据。
4. **Offset：** Offset 指的是消费者在每个分区中消费的位置，每一条消息在 partition 中的位置都由一个唯一的序号表示。
5. **Zookeeper：** Zookeeper 是一个分布式的，开放源码的分布式应用程序协调服务，它主要用来保存和同步数据和状态信息。Kafka 通过 Zookeeper 来保存和同步节点状态以及元数据信息。

---

一个简单的消息从生产者到消费者的旅程，串联起这些概念吧！这个过程就像你在书店里找一本书的过程。

1. **消息的生成（Producer）**  
   首先，生产者（Producer）生成一条消息，就像你在书店（Kafka）里写一封想要借书的信。
2. **发送到主题（Topic）**  
   然后，生产者将该消息发送到一个指定的主题（Topic），就如同你把信放到了朋友的信箱（Topic）里。
3. **分区存储（Partition）**  
   接着，这条消息会被存储在该主题的一个分区（Partition）里，这就像你的信被放在了信箱的一个小格子里。
4. **备份（Replica）**  
   为了保证消息的安全，在 Kafka 集群中，这个小格子（Partition）会在其他的书店（Broker）中有备份（Replica）。完成了这一步，就像你的信在其他朋友的信箱中也有一份。
5. **领导选择（Leader 和 Follower）**  
   然后在这些备份（Replica）中，会被选出一个 Leader，其他的都是 Follower。也就是说，其中一个朋友（Leader）被选出来负责处理你的信。
6. **消息消费（Consumer）**  
   最后，消费者（Consumer）会从这个 Leader 或者 Follower 那里获取消息并处理，就好像你的朋友（Consumer）打开他的信箱，找到你的信，打开并读取。
7. **消息偏移量（Offset）**  
   在这个过程中，每条消息在分区中的位置会被记录下来，这个位置叫做偏移量（Offset）。这就像每一封信都有一个唯一的邮件编号。

---

如果一家书店（Kafka）有两个顾客（消费者组 1），还有一个顾客（消费者组 2），在该书店有 100 本书（分区的数据），是如何选择某本书来读（消费）的。

在 Kafka 中，**消费者组与消费者和主题分区的关系**是这样的：每个消费者组中的消费者会在组内分配其读取的分区，而一个分区只能被消费者组中的一个消费者来读。同一消费者组内的消费者不读同分区的数据，这样可以避免重复读取，而不同消费者组可以读同一分区的数据，这样可以实现广播。每个消费者可以读取一个或多个分区。

具体到你的问题，消费者组 1 有两个消费者，那它们二人合起来可以读取所有的数据（100 条）；而消费者组 2 有一个消费者，它也可以读取所有的数据（100 条）。这是因为它们分属两个不同的消费者组，完全可以各读各的，不会影响到各自的进度。

也就是说，如果书店内有 100 本新书，消费者组 1 的两位顾客和消费者组 2 的一位顾客都可以从头到尾分别读完所有 100 本新书，读的顺序和速度都是他们自己决定的。就这样各自愉快的阅读。

# 发送数据过程

## 生产者发送消息到分区的过程

1. **生成消息（Producer）**  
   首先，生产者（Producer）在他的电脑上生成一条消息。这就像你写了一封邮件，准备发送出去。
2. **发送到 Leader**  
   然后，生产者将消息发送给分区的 Leader。也就是说，你点击了发送，邮件发送到了你的邮件服务器 (这里的 Leader)。
3. **备份到 Follower**  
   一旦 Leader 收到了这条消息，它会把它发送给所有的 Follower 进行备份，就像你的邮件服务器把你的邮件备份在了其他的服务器上。
4. **确认消息（ACK）** ：发布确认机制
   然后，根据设置的“acks”策略，可能会有三种情况：

   - 'acks=1' : Leader 在把消息写入本地日志后就确认消息。消息确认不等待所有 Follower 的备份都完成。这就像邮件服务器收到你的邮件后就告诉你邮件已发送，而并未等待所有的备份都完成。
   - 'acks=0' : Leader 不需要确认消息就可以了。这就像你的邮件一旦发送，你的邮件程序就会告诉你邮件已发送，而不关心邮件服务器有没有收到。
   - 'acks=-1' : Leader 会等待所有的 Follower 都备份了这个消息后才确认消息。这就像邮件服务器只有在所有的备份都完成后，才会告诉你邮件已发送。

在数据安全性和性能之间，需要做出平衡。'acks=1' 比 'acks=-1' 性能更好，但是在某些情况下可能会丢数据，例如 Leader 已经确认了消息，但是在 Follower 备份之前 Leader 宕机了。'acks=-1' 可能会慢一些，但是数据更安全。

4. **和 Zookeeper 打交道**  
   在 Kafka 集群中，Zookeeper 负责保存和协调 Kafka broker、主题、分区等元数据信息。例如，它可以追踪每个分区的 Leader 是谁。有了 Zookeeper，当 Leader 宕机时，Zookeeper 会从所有的 Follower 中选举出新的 Leader，来保证 Kafka 的高可用性。

这就是一条消息在 Kafka 中的发送和确认的过程。

## 消息与分区与高性能

就是描述消息面对多分区的发送策略。
当生产者准备发送消息到 Kafka 时，需要确定具体的分区。分区策略是 Kafka 在这里的重要机制。以下是几种常见的分区策略：

1. **指定分区 ID：**  如果在发送消息时显式指定了分区 ID，那么 Producer 就会将这条消息发送到指定的分区。
2. **带 Key 不指定分区 ID：**  当发送消息时提供了 Key，但没有指定分区 ID，那么 Kafka 将使用一个哈希函数将 Key 哈希到特定的分区。这意味着带有相同 Key 的所有消息都会被发布到同一个分区，这对于保证特定 Key 的消息顺序性非常有用。
3. **不带 Key 也不指定分区 ID：**  如果既没有提供 Key，也没指定分区 ID，那么 Kafka 将使用轮询策略（Round-Robin）来选择分区。也就是说，Producer 将消息依次发送到所有分区。

这些策略确保了有适当的负载均衡和可以对消息进行顺序处理，当然其也取决于你的具体业务需求。

## 生产信息关注的 API

# 写入缓冲区

# 消费数据

# 高可用
