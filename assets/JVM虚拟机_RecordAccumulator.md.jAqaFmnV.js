import{_ as c,o as e,c as o,R as d}from"./chunks/framework.7FlijoJG.js";const h=JSON.parse('{"title":"RecordAccumulator","description":"","frontmatter":{"title":"RecordAccumulator","date":"2024-01-21T12:46:17.000Z","Tags":["tech"],"Draft":true,"HideInList":false,"Feature":null,"IsTop":false},"headers":[],"relativePath":"JVM虚拟机/RecordAccumulator.md","filePath":"JVM虚拟机/RecordAccumulator.md","lastUpdated":1711296414000}'),r={name:"JVM虚拟机/RecordAccumulator.md"},t=d("<p><code>RecordAccumulator</code>的主要职责是将生产者发送的消息缓存起来，以便于批量发送，从而减少对 broker 的网络调用次数和相关开销，提高吞吐量。以下是<code>RecordAccumulator</code>如何控制消息的批处理和发送过程的关键点：</p><ol><li><p><strong>消息分批</strong>：当生产者调用<code>send()</code>方法发送消息时，<code>RecordAccumulator</code>将消息分配到对应的<code>RecordBatch</code>中。一个<code>RecordBatch</code>是一组要发送到相同 Topic 和 Partition 的消息集合。<code>RecordBatch</code>具有一定的大小限制（由<code>batch.size</code>配置指定），一旦达到这个限制，就会被发送出去。</p></li><li><p><strong>缓存管理</strong>：<code>RecordAccumulator</code>为每个 TopicPartition 维护对应的缓冲区。对于每次<code>send()</code>操作，它都会检查是否有现有的<code>RecordBatch</code>可以加入消息，如果没有，就会创建一个新的<code>RecordBatch</code>。<code>RecordAccumulator</code>还管理内部的内存缓冲区（受<code>buffer.memory</code>配置的限制）来存储尚未发送的<code>RecordBatch</code>。</p></li><li><p><strong>时间控制</strong>：<code>RecordAccumulator</code>还会检查<code>RecordBatch</code>里的消息是否已经滞留超过了预设的 linger.ms 配置。这个时间配置定义了生产者愿意等待更多消息加入到 batch 中的时间，以便填充 batch 和减少发送的频率。如果<code>batch</code>在这个时间之后仍未被填满，也会被发送。</p></li><li><p><strong>内存压力响应</strong>：如果<code>RecordAccumulator</code>用完了所有预设的内存缓冲区(buffer.memory), 任何进一步的<code>send()</code>调用都可能会被阻塞。这确保了生产者不会因内存不足而导致丢失消息，同时也是一种背压（backpressure）机制，提示应用程序减慢发送速度。</p></li><li><p><strong>Sender 线程交互</strong>：当<code>RecordBatch</code>准备好发送时，<code>RecordAccumulator</code>将它们移交给 Sender 线程。Sender 线程负责将这些<code>RecordBatch</code>批量发送到 Kafka 集群的 broker 上，然后处理确认响应，如果有必要，还会处理消息的重试。</p></li></ol><p>通过这些机制，<code>RecordAccumulator</code>有效地对生产者侧的出站消息流进行了批量处理和内存缓存管理，优化了生产者的性能，同时保持了对网络资源的有效利用。在配置<code>RecordAccumulator</code>时，需要根据应用的需求和生产者的行为选择合适的<code>batch.size</code>、<code>linger.ms</code>和<code>buffer.memory</code>的值，以达到最佳的性能效果。</p><hr><p>在Kafka生产者客户端中，<code>RecordAccumulator</code>是一个重要的组件，用来缓存即将发送到Kafka broker的消息。主要目的是提高生产者的吞吐量，它通过批量发送消息以减少网络请求的开销。</p><p><code>RecordAccumulator</code>中有一个或多个<code>RecordBatch</code>实例，每个<code>RecordBatch</code>对应于一个特定的TopicPartition（也就是一个topic的一个分区）。当生产者调用<code>send()</code>方法时，消息会被序列化后存入到对应<code>RecordBatch</code>中。</p><p><code>RecordAccumulator</code>会根据以下几个因素来决定何时发送一个<code>RecordBatch</code>:</p><ol><li><p><strong>大小（Size）</strong>：如果<code>RecordBatch</code>达到了预设的大小（batch.size）限制，它会被发送出去，即使还没有达到预设的时间（linger.ms）阈值。</p></li><li><p><strong>时间（Time）</strong>：linger.ms配置确定了一个消息可以在<code>RecordBatch</code>中的最长停留时间。即使<code>RecordBatch</code>没有被填满，一旦超过了这个时间限制，消息仍然会被发送。</p></li><li><p><strong>即将满（Almost Full）</strong>：即使一个<code>RecordBatch</code>没有完全被填满，也没有达到linger.ms指定的时间，<code>RecordAccumulator</code>也可能因为要为新消息腾出空间而提前发送。</p></li></ol><p>当<code>RecordBatch</code>已经准备好发送时，它们会被加入到一个发送队列（Sender Queue）中，由一个Sender线程负责实际的发送到Kafka集群。Sender线程会处理消息的发送，并等待broker的acknowledgement，这些都是异步完成的。如果消息发送失败，Sender线程也会处理重试逻辑。</p><p><code>RecordAccumulator</code>使用内存缓冲区暂存记录，所以当生产者的buffer.memory不足（所有缓冲区都满了）时，再调用send()方法就会阻塞，直到有足够的空间为止。这个机制保证了Kafka生产者不会因为暂时的缓冲区不足而丢失消息。</p><p>通过适当地配置<code>batch.size</code>、<code>linger.ms</code>和<code>buffer.memory</code>参数，开发者可以根据实际场景和性能需求调节生产者的行为。</p><p>在Kafka 0.11以后的版本中，<code>RecordAccumulator</code>的作用还涉及到了支持事务的能力，确保了消息在跨分区和跨会话的事务中的一致性。</p><p>总的来说，<code>RecordAccumulator</code>是Kafka生产者性能调优中的关键部分，有效用于控制和优化消息的批处理和发送过程。</p>",13),a=[t];function l(u,s,n,i,p,m){return e(),o("div",null,a)}const f=c(r,[["render",l]]);export{h as __pageData,f as default};
