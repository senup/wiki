import{_ as a,o as e,c as i,R as l}from"./chunks/framework.7FlijoJG.js";const k=JSON.parse('{"title":"kafka","description":"","frontmatter":{"title":"kafka","date":"2023-12-22T12:35:10.000Z","tags":["tech"],"Draft":true,"HideInList":false,"Feature":null,"IsTop":false},"headers":[],"relativePath":"interview/kafka2023.md","filePath":"interview/kafka2023.md","lastUpdated":1703743933000}'),o={name:"interview/kafka2023.md"},t=l('<h2 id="面试题" tabindex="-1">面试题 <a class="header-anchor" href="#面试题" aria-label="Permalink to &quot;面试题&quot;">​</a></h2><ol><li>保证 Kafka 的高可用：Kafka 支持集群模式，当某个节点（Kafka 的节点叫 Broker 啊！）出问题时，Kafka 会自动将该 Broker 上的分区转移到其他健康的 Broker 上。这就像你玩拼图，如果一块丢了，你可以用其它的来补齐。</li><li>避免重复消费：Kafka 的消息消费本质上是通过 offset（偏移量）来控制的。每个 Consumer 会专心记住它读到哪里，就像你阅读一本书，用书签标记了你阅读的位置一样。所以，只要不重置 offset，就不会重复消费消息。</li><li>确保幂等性：Kafka 0.11 版本以后支持了幂等写入，可以通过设置<code>enable.idempotence=true</code>来启用。消费端的幂等性则需要你在业务层面来保证，比如在数据库进行操作时，考虑将数据库操作设置为幂等操作。</li><li>保证消息的可靠性传输：Kafka 提供了消息持久化的功能，即把数据写入磁盘。并且还提供了数据副本，这就保证了即使某个 Broker 挂了，消息也不会丢失。你还可以设置 acks 参数来控制消息确认的模式，比如设置为&#39;all&#39;，就要等所有的 follower 都确认后才算消息写入成功。</li><li>消息丢失怎么办：Kafka 通过 Replica 机制保证了消息的安全，即使有 Broker 宕机，由于有 Replica，所以消息不会丢。但是如果你的 Replica 也丢了，那就真的找不回来了，尽管这种概率非常小。你可以设置更大的<code>replication.factor</code>来减少这种风险，就像你的钥匙丢了，如果你有备用钥匙，那就不怕了。</li></ol><hr><ol><li><p>保证消息的顺序性：在 Kafka 中，每个 Partition 内的消息是有序的，也就是说，消费者在消费某个 Partition 的消息时，是按照消息在 Partition 内的存放顺序进行消费的。就像你在超市购物，你可以先买鸡蛋，然后再买鸡，但在每个货架上，你肯定是从上而下，从左到右地取商品。</p></li><li><p>解决消息队列的延时问题：在 Kafka 中，一般通过增加 Partition 数量以及增加 Consumer 数量来提高吞吐量，进而降低延时。就像你想快速将一箱苹果分给大家，你会将苹果分成几堆，然后请几个人来帮忙分发。</p></li><li><p>解决消息队列过期失效问题：Kafka 提供了消息过期机制，你可以设置每个消息的保留时间，所以不用担心消息会无休止地堆积下去。就好比每个人都有生老病死，每个消息也有生存周期。</p></li><li><p>消息队列满了以后该怎么处理：在 Kafka 中，你可以通过加大存储空间来应对消息堆积。另一种方式是增加消费者数量，以更快地消费掉积压的消息。</p></li><li><p>几百万消息持续积压几小时怎么解决：同上，你可以试着去调整 Cluster 的大小，也就是增减 Broker 数，亦或者增加 Partition 数，调整你的消费者组来处理这个问题。</p></li><li><p>写一个消息队列的架构设计：这需要根据不同的场景和需求来考虑，我会考虑如下几点：</p><ul><li>高可用性：可以通过多副本以及 leader-follower 模式来保证。</li><li>高吞吐量：通过分区并行以及批量处理来提高处理效率。</li><li>消息持久化：保证消息不会丢失，可以将其落盘，并保证落盘操作的高效。</li><li>消费者群管理：提供有效的消费者群管理，使得消费者能根据自己的需求来高效地消费消息。</li></ul></li></ol><p>在顺序性、延时、过期失效、满队列和消息积压等问题上，你需要找到合适的平衡点。这就像走钢丝，需要细心保持平衡，才能走到对岸。</p><h2 id="消息中间件的作用" tabindex="-1">消息中间件的作用 <a class="header-anchor" href="#消息中间件的作用" aria-label="Permalink to &quot;消息中间件的作用&quot;">​</a></h2><h3 id="三大特性" tabindex="-1">三大特性 <a class="header-anchor" href="#三大特性" aria-label="Permalink to &quot;三大特性&quot;">​</a></h3><h4 id="解耦" tabindex="-1">解耦 <a class="header-anchor" href="#解耦" aria-label="Permalink to &quot;解耦&quot;">​</a></h4><p>生产者不需要直接对接消费者, 切断联系；</p><h4 id="异步" tabindex="-1">异步 <a class="header-anchor" href="#异步" aria-label="Permalink to &quot;异步&quot;">​</a></h4><p>生产者发送消息，消费者去同步消费消息 中间件天然，可以消费者不需要同步消息，生产者继续异步生产；</p><p>这点是消费的时间上来说的；</p><h4 id="削峰" tabindex="-1">削峰 <a class="header-anchor" href="#削峰" aria-label="Permalink to &quot;削峰&quot;">​</a></h4><p>中间件也能存储消息，因此进入队列后可以凭借着消费者的消费速度来定。</p><h2 id="消费队列的两种通信方式" tabindex="-1">消费队列的两种通信方式 <a class="header-anchor" href="#消费队列的两种通信方式" aria-label="Permalink to &quot;消费队列的两种通信方式&quot;">​</a></h2><ol><li>点对点（拉取方式）：在这种模式下，你可以把每个消息想象成一个小旗子，消费者就是在跑步的运动员。运动员每跑过一个小旗子就把它插在路边，而后面的运动员则根据路边插着小旗子的数量来调整自己的速度。在 Kafka 中，消费者消费消息后会提交 offset，以标记已经消费的消息。这种方式的优势在于可以完全适配消费速度，不会占满消费者内存。但是，消费者需要时刻监听队列的数据情况，这会带来一定的性能消耗。</li><li>发布订阅（推送方式）：在这种模式下，可以把消息比作是一个个汽球，而消费者就是消费者们手中的刺。消息队列不断地往消费者这边推汽球，消费者就用手中的刺扎破它们。消息队列无需关心消费者的消费速度，只要有新消息就推送出去，充分利用了消费者性能。但是，如果消费者处理不过来，可能会撑爆消费者的内存，造成大量消息堆积。</li></ol><p>至于 RabbitMQ 的拓扑图，你可以在网上搜索一下，找到你需要的信息。一般来说，RabbitMQ 的拓扑结构包括 Producer、Exchange、Queue 和 Consumer，其中 Producer 负责生产消息，Exchange 负责将消息路由到合适的 Queue，而 Consumer 则负责消费 Queue 中的消息。</p><h2 id="核心组件" tabindex="-1">核心组件 <a class="header-anchor" href="#核心组件" aria-label="Permalink to &quot;核心组件&quot;">​</a></h2><p>和 Zookeper</p><p><img src="https://bestkxt.oss-cn-guangzhou.aliyuncs.com/img/202312221249807.png" alt="image.png"></p><p><img src="https://bestkxt.oss-cn-guangzhou.aliyuncs.com/img/202312221249756.png" alt="image.png"></p><p><img src="https://bestkxt.oss-cn-guangzhou.aliyuncs.com/img/202312221250118.png" alt="image.png"></p><p><img src="https://bestkxt.oss-cn-guangzhou.aliyuncs.com/img/202312221250335.png" alt="image.png"></p><p><img src="https://bestkxt.oss-cn-guangzhou.aliyuncs.com/img/202312221251025.png" alt="image.png"></p><p><img src="https://bestkxt.oss-cn-guangzhou.aliyuncs.com/img/202312221252733.png" alt="image.png"></p><p><img src="https://bestkxt.oss-cn-guangzhou.aliyuncs.com/img/202312221252201.png" alt="image.png"> 画图</p><p><img src="https://bestkxt.oss-cn-guangzhou.aliyuncs.com/img/202312221254930.png" alt="image.png"></p><h1 id="生产数据" tabindex="-1">生产数据 <a class="header-anchor" href="#生产数据" aria-label="Permalink to &quot;生产数据&quot;">​</a></h1><p>来详细了解一下他们：</p><ol><li><p>配置项：</p><ul><li>bootstrap.servers：这是 Broker 的地址列表，Producer 需要连接到这些地址上去发送消息。</li><li>acks：这是消息确认机制，可以配置为 0, 1, 或者 all，根据需要选择一种级别。</li><li>retries：这是生产者在发送失败后，自动重试的次数。</li><li>batch.size：这是消息发送批次的大小。</li><li>linger.ms：消息等待发送的最长时间。</li><li>buffer.memory：这是生产者可以用来缓冲消息的内存大小。</li></ul></li><li><p>回调函数：当消息被发送之后，Kafka Producer 会调用这个回调函数来通知应用发送的结果，你可以在回调函数中做相应处理，例如记录日志或者统计发送成功的数量。</p></li><li><p>自定义拦截器：你可以通过实现 ProducerInterceptor 接口来自定义拦截器，拦截器中有以下三个方法：</p><ul><li>onSend：这个方法在消息被发送之前调用，你可以在这里进行消息的预处理。</li><li>onAcknowledgement：这个方法在消息被确认后调用，你可以在这里进行统计或者其他操作。</li><li>close：这个方法在生产者关闭时调用，一般可以用来做一些清理工作。</li></ul></li><li><p>自定义分区：你可以通过实现 Partitioner 接口来自定义分区器，分区器中有以下两个方法：</p><ul><li>partition: 这个方法用于决定消息应该发送到哪个分区。</li><li>close：这个方法和拦截器的 close 方法类似，都是在生产者关闭时进行调用的。</li></ul></li></ol><p>在发送消息的过程中，这些工具可以帮助你更好地控制消息的发送和处理</p><h2 id="消费数据" tabindex="-1">消费数据 <a class="header-anchor" href="#消费数据" aria-label="Permalink to &quot;消费数据&quot;">​</a></h2><ol><li>拉取数据：Kafka 中的 Consumer 从 Broker 拉取数据时，首先需要知道要拉取哪个 Topic 的哪个 Partition，同时需要提供一个 Offset。这就好像你去邮局取信，你需要知道你的邮箱号（Partition)，并要从哪封信开始取（Offset）。</li><li>查找数据的过程：Kafka 的数据存储是按照 Topic 和 Partition 来组织的。你可以把每个 Partition 想象成一本书，每个消息就是书中的一页，而 Offset 就是页码。消费者根据 Topic、Partition 和 Offset 可以精确地找到需要的数据。</li><li>文件结构：Kafka 中的每个 partition 对应一个文件夹，文件夹下面的每个文件代表一个 segment，每个 segment 文件对应两个文件，一个保存的是消息数据，一个保存的是索引。</li><li>记录消费的位置：Kafka 通过 Offset 来记录消费的位置。你可以将 Offset 想象成书签，这样，下次你继续阅读时，就可以直接从书签处开始。</li><li>消息的提交：消息提交就是更新 Offset。Kafka 支持同步提交和异步提交两种方式。同步提交虽然可靠，但效率低；异步提交效率高，但可能会丢失一些消息。</li><li>保证幂等性：在消费者端，幂等性通过业务逻辑来保证。例如，如果你的操作是向数据库中插入一条记录，那么你可以设置主键冲突时忽略，这样即使插入多次，数据库中也只会有一条记录。</li><li>提交与消费的顺序：消费消息和提交 offset 是两个步骤，通常我们消费完消息再提交 offset。这样可以确保如果在消费过程中出问题，我们可以通过重设 offset 再次消费该消息。</li><li>消费者重平衡：在 Consumer Group 中，如果有新的消费者加入、已有的消费者退出，或者订阅的 Topic 的 Partition 数目发生变化，那么就会触发消费者重平衡。处理方式，Kafka 提供了 Rebalance Listener，我们可以在 Listener 中定义在重平衡之前和之后要执行的操作。</li></ol><p>消费者在获取、处理、提交消息的过程中，就像是在跑马拉松。每个人都有自己的起点（Offset），每个人都需要准备（拉取消息），奔跑（处理消息），并记录自己跑过的路程（提交 Offset）。只有这样，才能确保跑者们在赛道上顺利进行。</p><h2 id="幂等性" tabindex="-1">幂等性 <a class="header-anchor" href="#幂等性" aria-label="Permalink to &quot;幂等性&quot;">​</a></h2><ol><li>写入的幂等性：Kafka 通过 <code>enable.idempotence=true</code> 确保消息生产者的幂等性。这个开关将保证不会因为网络问题等导致的重传造成重复写入。幂等性是由 producer id（pid）和序列号（seq id）一起保证的，Kafka broker 只接受序列号大于当前序列号的记录。</li><li>无法保证幂等的特殊情况：如果 producer 重启，pid 可能会变，这时同一条消息可能被重写。另一种场景是，如果消息没有 key，并且消息是轮询写入不同的 partition，由于 Kafka 只保证单个 partition 的顺序，所以可能无法保证全局的幂等性。</li><li>保证写入的 exactly once：确保精确一次消费，是通过“At least once”消费语义加上幂等性来完成。也就是说，Kafka 消费者做好消息消费后，可以将 offset 保存下来，即使重启消费者或者重复拉取消息，由于保存下来的 offset，也不会出现重复消费的情况。</li><li>零拷贝技术：在 Kafka 中，为了提高数据发送效率，采用了零拷贝技术，这就是将文件直接从磁盘转到 Socket，而不需要将文件从内核空间拷贝到用户空间，然后再从用户空间拷贝到内核空间，从而减少了 CPU 和内存的使用，提高了数据传输效率。</li><li>Kafka 优化发送消息：有几种策略可以用来优化 Kafka 的发送，比如可以通过调整 batch.size 和 linger.ms 来控制批次发送的大小和延迟，当数据量大到达到 batch.size 或者等待时间超过 linger.ms 时，批次就可以被发送。此外，还可以通过调整 max.request.size 来控制单个请求的最大字节数，从而避免因为单个请求过大而引发的问题。</li></ol><h2 id="重平衡" tabindex="-1">重平衡 <a class="header-anchor" href="#重平衡" aria-label="Permalink to &quot;重平衡&quot;">​</a></h2><p>关于消费者重平衡，就像大家在拿着一堆糖果，突然有人来了或走了，我们需要重新分配。不过，不用担心，让我来帮你解答：</p><ol><li><p>什么情况会发生消费者重平衡：消费者重平衡可能在以下几种情况下发生：</p><ul><li>新的消费者加入 Consumer Group</li><li>已存在的消费者离开 Consumer Group</li><li>订阅主题的分区数发生变化</li><li>订阅的主题列表发生变化</li></ul></li><li><p>分区和消费者关系：在 Kafka 中，每个消费者都会被分配一个或多个分区，分区的数量是可以动态调整的。消费者的数量不能超过分区的数量，否则会有消费者闲置。比如，你有 3 个分区和 2 个消费者，可能每个消费者都会获得至少一个分区，其中一个消费者可能会获取两个分区。</p></li><li><p>如何处理消费者重平衡：Kafka 已经很好地处理了消费者重平衡。当发生重平衡的时候，会触发一个再均衡的过程，包括三个阶段：再均衡前（Rebalance Before）、再均衡过程（Rebalance In Progress）、再均衡后（Rebalance After）。在 Rebalance Before 阶段，Consumer 会停止当前消费，提交当前的 offset；Rebalance In Progress 阶段，进行分区分配；Rebalance After 阶段，分配完成后，Consumer 开始从新的分区消费。</p></li><li><p>Kafka 提供了 3 种消费者分配策略：Range、RoundRobin 和 Sticky。Range 策略将所有 Topic 的分区排列成一个列表，然后按照消费者数量进行分割；RoundRobin 策略是把所有 Topic 的所有分区按照 round-robin 方式分配给消费者；Sticky 策略在尽可能减少触发 Rebalance 的同时，尽量均匀地分配分区。</p></li></ol><p>消费者重平衡就好比在为队员分配任务，目标就是让每个人都能有事情做，不会有人闲着，也不会有人忙不过来。这关键的是取得平衡，而这个平衡，正是 Kafka 在追求的。</p><h2 id="高可用" tabindex="-1">高可用 <a class="header-anchor" href="#高可用" aria-label="Permalink to &quot;高可用&quot;">​</a></h2><p>这就要提到 Kafka 中的 ISR、HW 和 LEO 以及它们之间的关系。</p><ol><li>ISR：ISR 代表 In-Sync Replica Set，它包含了所有与 leader 保持同步的、可用的 follower 副本，这个列表是动态变化的。</li><li>LEO：LEO 代表 Last End Offset，表示每个副本最后一个已经写入的消息的 offset。</li><li>HW：HW 代表 High Watermark，表示已经被所有 ISR 中的副本写入的、最小的 LEO。</li></ol><p>你提到的水位流程就是在 ISR、LEO 和 HW 之间形成的。比如说，我们的 ISR 里有三个副本 A，B，C。假设此时他们的 LEO 分别为 5，5，4，那么 HW 就是 4。只有当所有 ISR 里的所有副本的 LEO 都大于 4 时，HW 才会提升。</p><p>关于故障处理的问题，Kafka 有以下方式：</p><ol><li>当 follower 发生故障：如果 follower 发生故障，将会从 ISR 中被剔除，直到它重新从 Leader 同步数据，并且 LEO 超过 HW 后，才能再次被加入到 ISR 中。</li><li>当 leader 发生故障：如果 leader 发生故障，那么会从 ISR 中选举一个新的 leader，进行领导权的切换。</li></ol><p>关于消息确认的问题，ack 的值为-1 时，表示所有的副本都需要确认消息写入才算完成。此时如果仅过半数的副本确认，则不能确保所有副本都能正确写入数据，有可能数据丢失。</p><p>在配置中，我们可以指定允许的最大故障节点数。这个数值需要根据具体的需求进行设置，一般来说，这个数值不能大于 ISR 的数量，否则可能会导致数据丢失。</p><p>最后，关于领导者故障后的场景：如果 ack=0，那么生产者不会等待确认，所以不受影响；则如果 ack=1，那么只要领导者收到消息，生产者就可以确认消息发送成功，但如果此时领导者奔溃，就可能导致数据丢失；如果 ack=-1，那么需要所有的副本都确认后，生产者才能确认消息已发送成功，在领导者奔溃后，将会等待新的领导者选举。</p><h2 id="发送流程" tabindex="-1">发送流程 <a class="header-anchor" href="#发送流程" aria-label="Permalink to &quot;发送流程&quot;">​</a></h2><p>我们发送的消息在被真正发送到 Kafka 之前，会经过一系列的流程到达缓冲区。如果我们把消息看作是赛跑中的运动员，那么送到缓冲区的过程就像是他们的预备过程。</p><p>第一步，序列化操作。在 Kafka 的 Producer 中，Key 和 Value 是需要经过序列化操作的。序列化操作会把我们的消息转化为二进制形式，方便存储和传输。就好像赛跑运动员要穿上合适的服装，才能参加比赛。</p><p>第二步，构造 ProducerRecord。ProducerRecord 是包含了 Topic、Partition、Key、Value 的一个数据结构，他就像是赛跑比赛的报名表，上面记录着参赛者的所有信息。</p><p>第三步，使用自定义的 Partitioner 将消息分配给具体的 Partition。这就好像是把运动员分配到具体的跑道上。</p><p>第四步，将 ProducerRecord 放入缓冲区中。这个过程就好像把运动员安排在起跑线上，等待比赛的开始。</p><p>关于缓冲区，缓冲区在 Kafka 中起到缓存消息，提高批量发送效率的作用。他主要由以下部分构成：</p><ol><li>RecordAccumulator：这个是 Kafka 内部实现的一个累加器，他用于存储待发送的消息。你可以把他看作是一个运动员集训的营地。</li><li>Sender Thread：这个是负责将缓冲区中的数据发送到 Kafka 的线程。这个就好像是运动员的教练，负责指导运动员如何赛跑。</li></ol><p>总的来说，将消息发送到缓冲区并不是一个简单的操作。这其中，我们的消息需要经历序列化、构造 ProducerRecord、指定分区、添加到缓冲区等一系列的操作，才能真正的被发送到 Kafka 中。在这个过程中，我们需要充分理解每一个步骤的意义，这样我们才能更好地使用 Kafka。</p><h2 id="粘包与拆包" tabindex="-1">粘包与拆包 <a class="header-anchor" href="#粘包与拆包" aria-label="Permalink to &quot;粘包与拆包&quot;">​</a></h2><p>&quot;粘包&quot;和&quot;拆包&quot;是网络编程中非常常见的问题。他们就像是生活中乱插队和被强制中断的状况。</p><p>&quot;粘包&quot;是指发送方发送的若干包数据到达接收方时粘成一个包，接收方不清楚这是几个包的数据。好比你在超市买了很多商品，但是收银员把他们都算成了一个商品。</p><p>&quot;拆包&quot;是指发送方发送的一个完整的包，在发送过程中被拆成了两个或多个包，到达接收方时，接收方无法知道这是一个完整的包。好比你买的一个大包薯片，在途中被拆开成了好几小包。</p><p>关于如何解决粘包和拆包的问题，我们有以下几种方法：</p><ol><li><p>定长方式：每次发送固定长度的数据，不足的补空格。这种方式浪费网络资源，但是简单可行。</p></li><li><p>分隔符方式：每次发送的包数据后面都紧接一个特殊的分隔符，接收方收到数据后根据分隔符判断一个包数据是否结束。这种方式在发送的数据中不能包含分隔符，否则会出错。</p></li><li><p>头部标记长度方式：每次数据发送前，先发送一个头部信息，头部信息中包含整个数据包的长度。因此，Kafka里的Producer会在发送Batch的时候，把Batch的总长度写在Batch的头部，Broker就根据这个长度来断定&quot;粘包&quot;的情况。</p></li></ol><p>对于&quot;拆包&quot;问题，Kafka的解决办法是，Producer在发送Request的时候，如果第一次发送没有完成，它会记住已经发送的位置，下一次继续从这个位置发送。这样就保证了一个Request肯定会被完整发送。</p>',65),r=[t];function n(p,s,c,u,f,h){return e(),i("div",null,r)}const m=a(o,[["render",n]]);export{k as __pageData,m as default};
